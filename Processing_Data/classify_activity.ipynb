{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAPPING THE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jgm_6/.cache\\torch\\hub\\OxWearables_ssl-wearables_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Weights loaded\n",
      "Sequential(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv1d(3, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "    (1): ResBlock(\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Downsample()\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "    (1): ResBlock(\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Downsample()\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "    (1): ResBlock(\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Downsample()\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "    (1): ResBlock(\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Downsample()\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Downsample()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgm_6/.cache\\torch\\hub\\OxWearables_ssl-wearables_main\\hubconf.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(weight_path, map_location=my_device)\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = torch.hub.load(\n",
    "        'OxWearables/ssl-wearables', \n",
    "        'harnet5', \n",
    "        pretrained=True).feature_extractor\n",
    "\n",
    "print(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = False  # Freeze feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best trial:\n",
    "- Value: 0.7475\n",
    "- Params:\n",
    "  - lstm_layers: 2\n",
    "  - hidden_size: 256\n",
    "  - dropout: 0.26138219898271\n",
    "  - activation: ReLU\n",
    "  - lr: 0.0002829985470448175\n",
    "  - weight_decay: 2.1242103361847734e-05\n",
    "  - batch_size: 64\n",
    "  - optimizer: Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, feature_extractor, lstm_layers=1, hidden_size=256, dropout=0.2, activation='ReLU'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "        # Add a Linear layer to transform (batch_size, seq_length, 1) -> (batch_size, seq_length, 512)\n",
    "        self.feature_transformer = nn.Linear(1, 512)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=512, hidden_size=hidden_size, num_layers=lstm_layers,\n",
    "                            batch_first=True, dropout=dropout if lstm_layers > 1 else 0)\n",
    "        \n",
    "        activation_layer = {\n",
    "            'ReLU': nn.ReLU(),\n",
    "            'Tanh': nn.Tanh(),\n",
    "            'LeakyReLU': nn.LeakyReLU()\n",
    "        }[activation]\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 512),\n",
    "            activation_layer,\n",
    "            nn.Linear(512, 1024),\n",
    "            activation_layer,\n",
    "            nn.Linear(1024, 512),\n",
    "            activation_layer,\n",
    "            nn.Linear(512, 10),\n",
    "            # activation_layer,\n",
    "            # nn.Linear(256, 206)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        # print(\"Feature extractor output shape:\", features.shape)  # Debugging line to check the shape\n",
    "        features = self.feature_transformer(features)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(features)\n",
    "        lstm_last_output = lstm_out[:, -1, :]\n",
    "        output = self.classifier(lstm_last_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgm_6\\AppData\\Local\\Temp\\ipykernel_18872\\734222708.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classifier.load_state_dict(torch.load(calssifier_path))\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the classifier\n",
    "classifier = CustomModel(\n",
    "    feature_extractor=feature_extractor,\n",
    "    lstm_layers=2,\n",
    "    hidden_size=256,\n",
    "    dropout=0.26138219898271,\n",
    "    activation='ReLU'\n",
    ")\n",
    "\n",
    "# Load the state dictionary into the new instance\n",
    "calssifier_path = r'D:\\Rainbow_DQN_Test\\Test_DQN\\Data\\process_data\\best_model_10_meta_labels.pth'\n",
    "classifier.load_state_dict(torch.load(calssifier_path))\n",
    "# classifier.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Now `classifier` contains the saved weights\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD 5 SECONDS SEQUENCES FROM H5PY DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5(filepath, dataset_name):\n",
    "    with h5py.File(filepath, 'r') as h5file:\n",
    "        data = h5file[dataset_name][:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417840, 8, 150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X30 = read_h5(r'D:\\Rainbow_DQN_Test\\Test_DQN\\Data\\Process_canada_data\\P13_5_sec_30hz_sequences.h5', 'data')\n",
    "X30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.50025874, -0.50025874, -0.50025874, ..., -0.50267789,\n",
       "         -0.49709149, -0.50343321],\n",
       "        [ 0.15633085,  0.15633085,  0.15633085, ...,  0.16501594,\n",
       "          0.1678173 ,  0.14978904],\n",
       "        [ 0.82855353,  0.82855353,  0.82855353, ...,  0.8339162 ,\n",
       "          0.84018767,  0.82172327]],\n",
       "\n",
       "       [[-0.50025874, -0.48462565, -0.50025874, ..., -0.49865015,\n",
       "         -0.50316705, -0.48893228],\n",
       "        [ 0.15633085,  0.17196394,  0.15633085, ...,  0.17262687,\n",
       "          0.17304723,  0.16428411],\n",
       "        [ 0.82855353,  0.84418662,  0.84418662, ...,  0.83896935,\n",
       "          0.83700964,  0.8244901 ]],\n",
       "\n",
       "       [[-0.48462565, -0.50025874, -0.48462565, ..., -0.48773283,\n",
       "         -0.48779889, -0.5060838 ],\n",
       "        [ 0.15633085,  0.15633085,  0.15633085, ...,  0.21929406,\n",
       "          0.21948304,  0.21223335],\n",
       "        [ 0.82855353,  0.82855353,  0.82855353, ...,  0.82739054,\n",
       "          0.82804227,  0.82722642]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.73475502, -0.73475502, -0.73475502, ..., -0.71568423,\n",
       "         -0.72779923, -0.72887179],\n",
       "        [-0.43772639, -0.43772639, -0.43772639, ..., -0.43796183,\n",
       "         -0.43620048, -0.43900137],\n",
       "        [ 0.51589182,  0.51589182,  0.51589182, ...,  0.51535818,\n",
       "          0.51535818,  0.51535818]],\n",
       "\n",
       "       [[-0.71912193, -0.71912193, -0.71912193, ..., -0.71829966,\n",
       "         -0.71841093, -0.71837807],\n",
       "        [-0.43772639, -0.43772639, -0.45335948, ..., -0.43727361,\n",
       "         -0.43727361, -0.43727361],\n",
       "        [ 0.51589182,  0.51589182,  0.51589182, ...,  0.53156524,\n",
       "          0.52997393,  0.53259283]],\n",
       "\n",
       "       [[-0.71912193, -0.71912193, -0.71912193, ..., -0.71918072,\n",
       "         -0.71786632, -0.71869101],\n",
       "        [-0.43772639, -0.43772639, -0.43772639, ..., -0.43727361,\n",
       "         -0.43727361, -0.43727361],\n",
       "        [ 0.53152491,  0.53152491,  0.53152491, ...,  0.51425604,\n",
       "          0.51617352,  0.51467664]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_acc = X30[:, [2, 3, 4], :]  # Shape becomes (417840, 3, 320)\n",
    "X_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONE SEQUENCE DID WORK !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for the sequence: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "all_logits = []\n",
    "\n",
    "# Example: A single sequence from your dataset (replace with your actual data)\n",
    "# Shape: (8, 320) for one sequence\n",
    "single_sequence = X_acc[0].astype(np.float32)\n",
    "\n",
    "# Convert to PyTorch tensor and add a batch dimension\n",
    "single_sequence_tensor = torch.tensor(single_sequence, dtype=torch.float32).unsqueeze(0)  # Shape: (1, 3, 320)\n",
    "\n",
    "# Move model and data to the same device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = classifier.to(device)\n",
    "single_sequence_tensor = single_sequence_tensor.to(device)\n",
    "\n",
    "# Perform inference\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output = model(single_sequence_tensor)  # Shape: (1, num_classes)\n",
    "\n",
    "\n",
    "all_logits.extend(output.cpu().tolist())  # Convert to list and store\n",
    "\n",
    "# Get predicted class\n",
    "predicted_class = torch.argmax(output, dim=-1).item()\n",
    "print(f\"Predicted class for the sequence: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.7843915224075317,\n",
       "  -8.75704574584961,\n",
       "  -9.047948837280273,\n",
       "  0.5426174998283386,\n",
       "  -7.941391468048096,\n",
       "  -4.290830612182617,\n",
       "  -5.96685266494751,\n",
       "  -8.919855117797852,\n",
       "  1.9559062719345093,\n",
       "  -8.95846939086914]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "all_logits_tensor = torch.tensor(all_logits)\n",
    "\n",
    "# Find the highest class and logit for each sequence\n",
    "sequence_highest_classes = torch.argmax(all_logits_tensor, dim=-1).tolist()\n",
    "sequence_highest_logits = torch.max(all_logits_tensor, dim=-1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "[1.9559062719345093]\n"
     ]
    }
   ],
   "source": [
    "# Output\n",
    "print(sequence_highest_classes)  # [3, 1, 1]\n",
    "print(sequence_highest_logits)   # [4.2, 3.4, 2.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MORE SEQUENCES ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = X_acc.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417840"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed using batches.\n"
     ]
    }
   ],
   "source": [
    "# Define the required parameters\n",
    "all_logits = []\n",
    "results = []\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = classifier.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Process data in batches\n",
    "with torch.no_grad():\n",
    "    for i in range(sequences.shape[0]):\n",
    "        sequence = sequences[i]\n",
    "        \n",
    "        # Convert batch to PyTorch tensor\n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Move data and model to the same device\n",
    "        sequence_tensor = sequence_tensor.to(device)\n",
    "        \n",
    "        # Classify the batch\n",
    "        output = model(sequence_tensor)\n",
    "\n",
    "        # Store logits for this batch\n",
    "        all_logits.extend(output.cpu().tolist())  # Convert to list and store\n",
    "\n",
    "        predicted_class = torch.argmax(output, dim=-1).item()\n",
    "\n",
    "        # Append results\n",
    "        results.append(predicted_class)\n",
    "\n",
    "print(\"Classification completed using batches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_array = np.array(all_logits)\n",
    "results_array = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.78439152, -8.75704575, -9.04794884,  0.5426175 , -7.94139147,\n",
       "       -4.29083061, -5.96685266, -8.91985512,  1.95590627, -8.95846939])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE IN NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('P13_classifications', array=results_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('P13_class_probs', array=logits_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
