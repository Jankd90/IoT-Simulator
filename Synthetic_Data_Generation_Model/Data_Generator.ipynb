{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LSTM Autoencoder Model\n",
    "class StatefulLSTM_Autoencoder(nn.Module):\n",
    "    def __init__(self, num_channels, hidden_size, num_layers, feature_dim=10):\n",
    "        super(StatefulLSTM_Autoencoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.LSTM(input_size=num_channels, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, feature_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc2 = nn.Linear(feature_dim, hidden_size)\n",
    "        self.decoder = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_size, num_channels)\n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        \"\"\"Create initial hidden state tensors (h_0, c_0)\"\"\"\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))\n",
    "\n",
    "    def forward(self, x, encoder_hidden, decoder_hidden):\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, num_samples, num_channels)\n",
    "\n",
    "        # Encoder forward pass with provided hidden state\n",
    "        _, encoder_hidden = self.encoder(x, encoder_hidden)\n",
    "        # print(\"Encoder hidden shape:\", [h.shape for h in encoder_hidden])  # Print shapes of h_0 and c_0\n",
    "\n",
    "        # Feature bottleneck\n",
    "        features = self.fc1(encoder_hidden[0][-1])  # Last layer's hidden state\n",
    "        # print(features.shape)\n",
    "        expanded_features = self.fc2(features).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        # print(expanded_features.shape)\n",
    "        # print(\"Decoder hidden shape:\", [h.shape for h in decoder_hidden])  # Print shapes of h_0 and c_0\n",
    "\n",
    "        # Decoder forward pass with provided hidden state\n",
    "        decoded_output, decoder_hidden = self.decoder(expanded_features, decoder_hidden)\n",
    "        decoded_output = self.fc_out(decoded_output)\n",
    "\n",
    "        # Detach hidden states to prevent backpropagation across batches\n",
    "        encoder_hidden = (encoder_hidden[0].detach(), encoder_hidden[1].detach())\n",
    "        decoder_hidden = (decoder_hidden[0].detach(), decoder_hidden[1].detach())\n",
    "\n",
    "        return decoded_output.permute(0, 2, 1), features, encoder_hidden, decoder_hidden  # (batch_size, num_channels, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reconstructed data to HDF5\n",
    "def save_data(filepath, data):\n",
    "    with h5py.File(filepath, 'w') as f:\n",
    "        f.create_dataset('reconstructed_data', data=data)\n",
    "    print(f\"Reconstructed data saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load Data\n",
    "def load_data(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        X = f['data'][:]\n",
    "    # data = torch.from_numpy(X).float()  # Convert to PyTorch tensor\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(X, order):\n",
    "    # Reshape for fitting: (samples * features, timesteps) â†’ (20*6, 150)\n",
    "    # X_reshaped = X.reshape(-1, X.shape[2])  \n",
    "\n",
    "    # Fit scaler on entire dataset\n",
    "    # scaler = StandardScaler()\n",
    "    # X_standardized = scaler.fit_transform(X_reshaped)\n",
    "\n",
    "    # Reshape back to (20, 6, 150)\n",
    "    # X_standardized = X_standardized.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "\n",
    "    # Reorder using NumPy indexing\n",
    "    X_reorderd = X[:, order, :]\n",
    "\n",
    "    data = torch.from_numpy(X_reorderd).float()  # Convert to PyTorch tensor\n",
    "\n",
    "    # Print shape to confirm it remains unchanged\n",
    "    print(\"Original shape:\", X.shape)\n",
    "    print(\"Standardized and reordered shape:\", data.shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model function\n",
    "def load_model(filepath, num_channels, hidden_size, num_layers, feature_dim):\n",
    "    model = StatefulLSTM_Autoencoder(num_channels, hidden_size, num_layers, feature_dim)\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def run_inference(model, data_loader):\n",
    "    model.to(device)\n",
    "    all_reconstructed = []\n",
    "    all_features = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Initialize hidden states\n",
    "        batch_size = next(iter(data_loader))[0].size(0)\n",
    "        encoder_hidden = model.init_hidden(batch_size, device)\n",
    "        decoder_hidden = model.init_hidden(batch_size, device)\n",
    "\n",
    "        for inputs, _ in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            decoded, features, encoder_hidden, decoder_hidden = model(inputs, encoder_hidden, decoder_hidden)\n",
    "            all_reconstructed.append(decoded.cpu().numpy())  # Store the reconstructed output\n",
    "            all_features.append(features.cpu().numpy())  # Store the reconstructed output\n",
    "\n",
    "\n",
    "    return np.concatenate(all_reconstructed, axis=0), np.concatenate(all_features, axis=0)  # Combine all outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (417840, 6, 150)\n",
      "Standardized and reordered shape: torch.Size([417840, 6, 150])\n",
      "Reconstructed data saved to D:\\Ali_Thesis\\synthetic_data_generation\\Data\\Process_canada_data\\features_extraction\\trial_12\\reconstructed_data.h5\n",
      "Reconstructed Data Shape: (417840, 6, 150)\n",
      "Reconstructed Data Shape: (417840, 10)\n"
     ]
    }
   ],
   "source": [
    "# Main execution for inference\n",
    "# Load the data\n",
    "file_path = r\"D:\\Ali_Thesis\\synthetic_data_generation\\Data\\Process_canada_data\\P13_5_sec_30hz_sequences_sensor_data_std_normalized.h5\"\n",
    "X = load_data(file_path)\n",
    "\n",
    "order = [1, 2, 3, 4, 5, 0]  # Acc_X, Acc_y, Acc_z, BvP, TEMP, EDA\n",
    "data = process_data(X, order)\n",
    "\n",
    "num_channels = data.shape[1]\n",
    "\n",
    "# Define batch size (can be same as used during training)\n",
    "batch_size = 16  # Or any suitable batch size for inference\n",
    "data_loader = DataLoader(TensorDataset(data, data), batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# Load the trained model\n",
    "model_path = r\"D:\\Ali_Thesis\\synthetic_data_generation\\Data\\Process_canada_data\\features_extraction\\trial_12\\lstm_autoencoder.pth\"\n",
    "model = load_model(model_path, num_channels, hidden_size=64, num_layers=2, feature_dim=10)\n",
    "\n",
    "# Run inference\n",
    "reconstructed_data, features = run_inference(model, data_loader)\n",
    "\n",
    "# Save the reconstructed data to an HDF5 file\n",
    "save_data(r'D:\\Ali_Thesis\\synthetic_data_generation\\Data\\Process_canada_data\\features_extraction\\trial_12\\reconstructed_data.h5', reconstructed_data)\n",
    "np.savez_compressed(r'D:\\Ali_Thesis\\synthetic_data_generation\\Data\\Process_canada_data\\features_extraction\\trial_12\\features.npz', features)\n",
    "\n",
    "# Optionally: save or visualize the reconstructed data\n",
    "print(\"Reconstructed Data Shape:\", reconstructed_data.shape)\n",
    "print(\"Reconstructed Data Shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
